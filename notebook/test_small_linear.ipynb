{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComposableModel(\n",
       "  (linear): Mlp(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import ComposableModel\n",
    "from util import read_config\n",
    "\n",
    "model_cfg = read_config('notebook/linear.yaml')\n",
    "model = ComposableModel(\"linear\", model_cfg.modules)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9733],\n",
      "        [0.9685],\n",
      "        [0.1605],\n",
      "        [0.4111],\n",
      "        [0.0207],\n",
      "        [0.2344],\n",
      "        [0.2591],\n",
      "        [0.7195],\n",
      "        [0.3141],\n",
      "        [0.0871],\n",
      "        [0.3372],\n",
      "        [0.8402],\n",
      "        [0.6264],\n",
      "        [0.7503],\n",
      "        [0.5292],\n",
      "        [0.7963],\n",
      "        [0.1015],\n",
      "        [0.4873],\n",
      "        [0.1663],\n",
      "        [0.3113],\n",
      "        [0.4994],\n",
      "        [0.1190],\n",
      "        [0.3391],\n",
      "        [0.5953],\n",
      "        [0.8303],\n",
      "        [0.0444],\n",
      "        [0.1847],\n",
      "        [0.9211],\n",
      "        [0.1615],\n",
      "        [0.1352],\n",
      "        [0.1553],\n",
      "        [0.1558],\n",
      "        [0.1173],\n",
      "        [0.0704],\n",
      "        [0.8128],\n",
      "        [0.6976],\n",
      "        [0.0321],\n",
      "        [0.2963],\n",
      "        [0.9549],\n",
      "        [0.6143],\n",
      "        [0.8409],\n",
      "        [0.5664],\n",
      "        [0.4373],\n",
      "        [0.5050],\n",
      "        [0.3816],\n",
      "        [0.7072],\n",
      "        [0.0177],\n",
      "        [0.4176],\n",
      "        [0.8027],\n",
      "        [0.4672],\n",
      "        [0.8724],\n",
      "        [0.0879],\n",
      "        [0.3590],\n",
      "        [0.9375],\n",
      "        [0.4465],\n",
      "        [0.4393],\n",
      "        [0.1694],\n",
      "        [0.8312],\n",
      "        [0.3152],\n",
      "        [0.4821],\n",
      "        [0.3595],\n",
      "        [0.8255],\n",
      "        [0.0643],\n",
      "        [0.9123],\n",
      "        [0.9169],\n",
      "        [0.0608],\n",
      "        [0.5640],\n",
      "        [0.6540],\n",
      "        [0.9540],\n",
      "        [0.8503],\n",
      "        [0.3358],\n",
      "        [0.8221],\n",
      "        [0.7675],\n",
      "        [0.7903],\n",
      "        [0.7701],\n",
      "        [0.7252],\n",
      "        [0.8621],\n",
      "        [0.7732],\n",
      "        [0.7365],\n",
      "        [0.2520],\n",
      "        [0.6399],\n",
      "        [0.1920],\n",
      "        [0.5524],\n",
      "        [0.3472],\n",
      "        [0.8452],\n",
      "        [0.7125],\n",
      "        [0.6418],\n",
      "        [0.5517],\n",
      "        [0.4856],\n",
      "        [0.4181],\n",
      "        [0.5608],\n",
      "        [0.3007],\n",
      "        [0.2373],\n",
      "        [0.3310],\n",
      "        [0.5238],\n",
      "        [0.3766],\n",
      "        [0.7137],\n",
      "        [0.4626],\n",
      "        [0.8993],\n",
      "        [0.6188]])\n",
      "tensor([[2.9545],\n",
      "        [2.8888],\n",
      "        [1.3904],\n",
      "        [1.6726],\n",
      "        [1.1250],\n",
      "        [1.5566],\n",
      "        [1.4843],\n",
      "        [2.3077],\n",
      "        [1.7414],\n",
      "        [1.2529],\n",
      "        [1.7182],\n",
      "        [2.5560],\n",
      "        [2.2355],\n",
      "        [2.3591],\n",
      "        [1.9386],\n",
      "        [2.5484],\n",
      "        [1.2615],\n",
      "        [2.0014],\n",
      "        [1.3571],\n",
      "        [1.6879],\n",
      "        [2.1037],\n",
      "        [1.1082],\n",
      "        [1.6226],\n",
      "        [2.1163],\n",
      "        [2.5632],\n",
      "        [1.0396],\n",
      "        [1.2702],\n",
      "        [2.7790],\n",
      "        [1.3053],\n",
      "        [1.2266],\n",
      "        [1.2331],\n",
      "        [1.3597],\n",
      "        [1.0521],\n",
      "        [1.0549],\n",
      "        [2.6384],\n",
      "        [2.4009],\n",
      "        [1.1139],\n",
      "        [1.5284],\n",
      "        [2.8060],\n",
      "        [2.2146],\n",
      "        [2.7932],\n",
      "        [2.0409],\n",
      "        [1.9233],\n",
      "        [2.0489],\n",
      "        [1.6645],\n",
      "        [2.3909],\n",
      "        [1.0492],\n",
      "        [1.8547],\n",
      "        [2.6439],\n",
      "        [2.0558],\n",
      "        [2.8036],\n",
      "        [1.0560],\n",
      "        [1.6749],\n",
      "        [2.9105],\n",
      "        [2.0168],\n",
      "        [1.7300],\n",
      "        [1.2349],\n",
      "        [2.7455],\n",
      "        [1.7022],\n",
      "        [2.0810],\n",
      "        [1.7006],\n",
      "        [2.6149],\n",
      "        [1.1221],\n",
      "        [2.6376],\n",
      "        [2.7732],\n",
      "        [1.2125],\n",
      "        [2.1425],\n",
      "        [2.2900],\n",
      "        [2.9250],\n",
      "        [2.8678],\n",
      "        [1.7934],\n",
      "        [2.4539],\n",
      "        [2.5311],\n",
      "        [2.4669],\n",
      "        [2.5925],\n",
      "        [2.4918],\n",
      "        [2.6671],\n",
      "        [2.5953],\n",
      "        [2.4505],\n",
      "        [1.6547],\n",
      "        [2.2801],\n",
      "        [1.5203],\n",
      "        [2.0978],\n",
      "        [1.7547],\n",
      "        [2.5230],\n",
      "        [2.3420],\n",
      "        [2.2338],\n",
      "        [2.0538],\n",
      "        [2.1467],\n",
      "        [1.8045],\n",
      "        [2.1948],\n",
      "        [1.4547],\n",
      "        [1.3523],\n",
      "        [1.6832],\n",
      "        [1.9490],\n",
      "        [1.7748],\n",
      "        [2.5746],\n",
      "        [1.8559],\n",
      "        [2.7630],\n",
      "        [2.2452]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "x = torch.from_numpy(np.random.rand(100, 1).astype(np.float32))\n",
    "y = 2 * x + 1 + 0.1 * torch.randn(100, 1)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[1.2118],\n",
       "         [1.2098],\n",
       "         [0.8666],\n",
       "         [0.9730],\n",
       "         [0.8072],\n",
       "         [0.8980],\n",
       "         [0.9085],\n",
       "         [1.1040],\n",
       "         [0.9318],\n",
       "         [0.8354],\n",
       "         [0.9417],\n",
       "         [1.1553],\n",
       "         [1.0645],\n",
       "         [1.1171],\n",
       "         [1.0232],\n",
       "         [1.1366],\n",
       "         [0.8415],\n",
       "         [1.0054],\n",
       "         [0.8691],\n",
       "         [0.9306],\n",
       "         [1.0105],\n",
       "         [0.8490],\n",
       "         [0.9425],\n",
       "         [1.0513],\n",
       "         [1.1511],\n",
       "         [0.8173],\n",
       "         [0.8769],\n",
       "         [1.1896],\n",
       "         [0.8670],\n",
       "         [0.8558],\n",
       "         [0.8644],\n",
       "         [0.8646],\n",
       "         [0.8482],\n",
       "         [0.8283],\n",
       "         [1.1437],\n",
       "         [1.0947],\n",
       "         [0.8121],\n",
       "         [0.9243],\n",
       "         [1.2040],\n",
       "         [1.0593],\n",
       "         [1.1556],\n",
       "         [1.0390],\n",
       "         [0.9841],\n",
       "         [1.0129],\n",
       "         [0.9605],\n",
       "         [1.0988],\n",
       "         [0.8059],\n",
       "         [0.9758],\n",
       "         [1.1394],\n",
       "         [0.9969],\n",
       "         [1.1690],\n",
       "         [0.8358],\n",
       "         [0.9509],\n",
       "         [1.1966],\n",
       "         [0.9881],\n",
       "         [0.9850],\n",
       "         [0.8704],\n",
       "         [1.1515],\n",
       "         [0.9323],\n",
       "         [1.0032],\n",
       "         [0.9511],\n",
       "         [1.1490],\n",
       "         [0.8258],\n",
       "         [1.1859],\n",
       "         [1.1878],\n",
       "         [0.8243],\n",
       "         [1.0380],\n",
       "         [1.0762],\n",
       "         [1.2036],\n",
       "         [1.1596],\n",
       "         [0.9410],\n",
       "         [1.1476],\n",
       "         [1.1244],\n",
       "         [1.1341],\n",
       "         [1.1255],\n",
       "         [1.1065],\n",
       "         [1.1646],\n",
       "         [1.1268],\n",
       "         [1.1112],\n",
       "         [0.9055],\n",
       "         [1.0702],\n",
       "         [0.8800],\n",
       "         [1.0330],\n",
       "         [0.9459],\n",
       "         [1.1574],\n",
       "         [1.1011],\n",
       "         [1.0710],\n",
       "         [1.0328],\n",
       "         [1.0047],\n",
       "         [0.9760],\n",
       "         [1.0366],\n",
       "         [0.9261],\n",
       "         [0.8992],\n",
       "         [0.9390],\n",
       "         [1.0209],\n",
       "         [0.9584],\n",
       "         [1.1016],\n",
       "         [0.9949],\n",
       "         [1.1804],\n",
       "         [1.0612]], grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1633436679840088\n",
      "100 0.06514652818441391\n",
      "200 0.042637500911951065\n",
      "300 0.02715247869491577\n",
      "400 0.01718084141612053\n",
      "500 0.011729205958545208\n",
      "600 0.009142213501036167\n",
      "700 0.008066040463745594\n",
      "800 0.007671847939491272\n",
      "900 0.007544530555605888\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)[\"x\"]\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[1.9519]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0141], requires_grad=True))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.mlp[0].weight, model.linear.mlp[0].bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
